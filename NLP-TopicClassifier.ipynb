{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3ae37fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65e0afaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: Mamatha Devineni Ratnam <mr47+@andrew.cmu.edu>\n",
      "Subject: Pens fans reactions\n",
      "Organization: Post Office, Carnegie Mellon, Pittsburgh, PA\n",
      "Lines: 12\n",
      "NNTP-Posting-Host: po4.andrew.cmu.edu\n",
      "\n",
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
      "are killing those Devils worse than I thought. Jagr just showed you why\n",
      "he is much better than his regular season stats. He is also a lot\n",
      "fo fun to watch in the playoffs. Bowman should let JAgr have a lot of\n",
      "fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\n",
      "regular season game.          PENS RULE!!!\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "From: mblawson@midway.ecn.uoknor.edu (Matthew B Lawson)\n",
      "Subject: Which high-performance VLB video card?\n",
      "Summary: Seek recommendations for VLB video card\n",
      "Nntp-Posting-Host: midway.ecn.uoknor.edu\n",
      "Organization: Engineering Computer Network, University of Oklahoma, Norman, OK, USA\n",
      "Keywords: orchid, stealth, vlb\n",
      "Lines: 21\n",
      "\n",
      "  My brother is in the market for a high-performance video card that supports\n",
      "VESA local bus with 1-2MB RAM.  Does anyone have suggestions/ideas on:\n",
      "\n",
      "  - Diamond Stealth Pro Local Bus\n",
      "\n",
      "  - Orchid Farenheit 1280\n",
      "\n",
      "  - ATI Graphics Ultra Pro\n",
      "\n",
      "  - Any other high-performance VLB card\n",
      "\n",
      "\n",
      "Please post or email.  Thank you!\n",
      "\n",
      "  - Matt\n",
      "\n",
      "-- \n",
      "    |  Matthew B. Lawson <------------> (mblawson@essex.ecn.uoknor.edu)  |   \n",
      "  --+-- \"Now I, Nebuchadnezzar, praise and exalt and glorify the King  --+-- \n",
      "    |   of heaven, because everything he does is right and all his ways  |   \n",
      "    |   are just.\" - Nebuchadnezzar, king of Babylon, 562 B.C.           |   \n",
      "\n",
      "-----------------------------------\n",
      "From: hilmi-er@dsv.su.se (Hilmi Eren)\n",
      "Subject: Re: ARMENIA SAYS IT COULD SHOOT DOWN TURKISH PLANES (Henrik)\n",
      "Lines: 95\n",
      "Nntp-Posting-Host: viktoria.dsv.su.se\n",
      "Reply-To: hilmi-er@dsv.su.se (Hilmi Eren)\n",
      "Organization: Dept. of Computer and Systems Sciences, Stockholm University\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "|>The student of \"regional killings\" alias Davidian (not the Davidian religios sect) writes:\n",
      "\n",
      "\n",
      "|>Greater Armenia would stretch from Karabakh, to the Black Sea, to the\n",
      "|>Mediterranean, so if you use the term \"Greater Armenia\" use it with care.\n",
      "\n",
      "\n",
      "\tFinally you said what you dream about. Mediterranean???? That was new....\n",
      "\tThe area will be \"greater\" after some years, like your \"holocaust\" numbers......\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "|>It has always been up to the Azeris to end their announced winning of Karabakh \n",
      "|>by removing the Armenians! When the president of Azerbaijan, Elchibey, came to \n",
      "|>power last year, he announced he would be be \"swimming in Lake Sevan [in \n",
      "|>Armeniaxn] by July\".\n",
      "\t\t*****\n",
      "\tIs't July in USA now????? Here in Sweden it's April and still cold.\n",
      "\tOr have you changed your calendar???\n",
      "\n",
      "\n",
      "|>Well, he was wrong! If Elchibey is going to shell the \n",
      "|>Armenians of Karabakh from Aghdam, his people will pay the price! If Elchibey \n",
      "\t\t\t\t\t\t    ****************\n",
      "|>is going to shell Karabakh from Fizuli his people will pay the price! If \n",
      "\t\t\t\t\t\t    ******************\n",
      "|>Elchibey thinks he can get away with bombing Armenia from the hills of \n",
      "|>Kelbajar, his people will pay the price. \n",
      "\t\t\t    ***************\n",
      "\n",
      "\n",
      "\tNOTHING OF THE MENTIONED IS TRUE, BUT LET SAY IT's TRUE.\n",
      "\t\n",
      "\tSHALL THE AZERI WOMEN AND CHILDREN GOING TO PAY THE PRICE WITH\n",
      "\t\t\t\t\t\t    **************\n",
      "\tBEING RAPED, KILLED AND TORTURED BY THE ARMENIANS??????????\n",
      "\t\n",
      "\tHAVE YOU HEARDED SOMETHING CALLED: \"GENEVA CONVENTION\"???????\n",
      "\tYOU FACIST!!!!!\n",
      "\n",
      "\n",
      "\n",
      "\tOhhh i forgot, this is how Armenians fight, nobody has forgot\n",
      "\tyou killings, rapings and torture against the Kurds and Turks once\n",
      "\tupon a time!\n",
      "      \n",
      "       \n",
      "\n",
      "|>And anyway, this \"60 \n",
      "|>Kurd refugee\" story, as have other stories, are simple fabrications sourced in \n",
      "|>Baku, modified in Ankara. Other examples of this are Armenia has no border \n",
      "|>with Iran, and the ridiculous story of the \"intercepting\" of Armenian military \n",
      "|>conversations as appeared in the New York Times supposedly translated by \n",
      "|>somebody unknown, from Armenian into Azeri Turkish, submitted by an unnamed \n",
      "|>\"special correspondent\" to the NY Times from Baku. Real accurate!\n",
      "\n",
      "Ohhhh so swedish RedCross workers do lie they too? What ever you say\n",
      "\"regional killer\", if you don't like the person then shoot him that's your policy.....l\n",
      "\n",
      "\n",
      "|>[HE]\tSearch Turkish planes? You don't know what you are talking about.<-------\n",
      "|>[HE]\tsince it's content is announced to be weapons? \t\t\t\ti\t \n",
      "\t\t\t\t\t\t\t\t\t\ti\n",
      "|>Well, big mouth Ozal said military weapons are being provided to Azerbaijan\ti\n",
      "|>from Turkey, yet Demirel and others say no. No wonder you are so confused!\ti\n",
      "\t\t\t\t\t\t\t\t\t\ti\n",
      "\t\t\t\t\t\t\t\t\t\ti\n",
      "\tConfused?????\t\t\t\t\t\t\t\ti\n",
      "\tYou facist when you delete text don't change it, i wrote:\t\ti\n",
      "\t\t\t\t\t\t\t\t\t\ti\n",
      "        Search Turkish planes? You don't know what you are talking about.\ti\n",
      "        Turkey's government has announced that it's giving weapons  <-----------i\n",
      "        to Azerbadjan since Armenia started to attack Azerbadjan\t\t\n",
      "        it self, not the Karabag province. So why search a plane for weapons\t\n",
      "        since it's content is announced to be weapons?   \n",
      "\n",
      "\tIf there is one that's confused then that's you! We have the right (and we do)\n",
      "\tto give weapons to the Azeris, since Armenians started the fight in Azerbadjan!\n",
      " \n",
      "\n",
      "|>You are correct, all Turkish planes should be simply shot down! Nice, slow\n",
      "|>moving air transports!\n",
      "\n",
      "\tShoot down with what? Armenian bread and butter? Or the arms and personel \n",
      "\tof the Russian army?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hilmi Eren\n",
      "Stockholm University\n",
      "\n",
      "-----------------------------------\n",
      "From: guyd@austin.ibm.com (Guy Dawson)\n",
      "Subject: Re: IDE vs SCSI, DMA and detach\n",
      "Originator: guyd@pal500.austin.ibm.com\n",
      "Organization: IBM Austin\n",
      "Lines: 60\n",
      "\n",
      "\n",
      "In article <1993Apr19.034517.12820@julian.uwo.ca>, wlsmith@valve.heart.rri.uwo.ca (Wayne Smith) writes:\n",
      "> In article <RICHK.93Apr15075248@gozer.grebyn.com> richk@grebyn.com (Richard Krehbiel) writes:\n",
      "> >>     Can anyone explain in fairly simple terms why, if I get OS/2, I might \n",
      "> >>   need an SCSI controler rather than an IDE.  Will performance suffer that\n",
      "> >>   much?  For a 200MB or so drive?  If I don't have a tape drive or CD-ROM?\n",
      "> >>   Any help would be appreciated.\n",
      "> \n",
      "> >So, when you've got multi-tasking, you want to increase performance by\n",
      "> >increasing the amount of overlapping you do.\n",
      "> >\n",
      "> >One way is with DMA or bus mastering.  Either of these make it\n",
      "> >possible for I/O devices to move their data into and out of memory\n",
      "> >without interrupting the CPU.  The alternative is for the CPU to move\n",
      "> >the data.  There are several SCSI interface cards that allow DMA and\n",
      "> >bus mastering.\n",
      ">  ^^^^^^^^^^^^\n",
      "> How do you do bus-mastering on the ISA bus?\n",
      "> \n",
      "> >IDE, however, is defined by the standard AT interface\n",
      "> >created for the IBM PC AT, which requires the CPU to move all the data\n",
      "> >bytes, with no DMA.\n",
      "> \n",
      "> If we're talking ISA (AT) bus here, then you can only have 1 DMA channel\n",
      "> active at any one time, presumably transferring data from a single device.\n",
      "> So even though you can have at least 7 devices on a SCSI bus, explain how\n",
      "> all 7 of those devices can to DMA transfers through a single SCSI card\n",
      "> to the ISA-AT bus at the same time.\n",
      "\n",
      "Think!\n",
      "\n",
      "It's the SCSI card doing the DMA transfers NOT the disks...\n",
      "\n",
      "The SCSI card can do DMA transfers containing data from any of the SCSI devices\n",
      "it is attached when it wants to.\n",
      "\n",
      "An important feature of SCSI is the ability to detach a device. This frees the\n",
      "SCSI bus for other devices. This is typically used in a multi-tasking OS to\n",
      "start transfers on several devices. While each device is seeking the data the\n",
      "bus is free for other commands and data transfers. When the devices are\n",
      "ready to transfer the data they can aquire the bus and send the data.\n",
      "\n",
      "On an IDE bus when you start a transfer the bus is busy until the disk has seeked\n",
      "the data and transfered it. This is typically a 10-20ms second lock out for other\n",
      "processes wanting the bus irrespective of transfer time.\n",
      "\n",
      "> \n",
      "> Also, I'm still trying to track down a copy of IBM's AT reference book,\n",
      "> but from their PC technical manual (page 2-93):\n",
      "> \n",
      "> \"The (FDD) adapter is buffered on the I.O bus and uses the System Board\n",
      "> direct memory access (DMA) for record data transfers.\"\n",
      "> I expect to see something similar for the PC-AT HDD adapter.  \n",
      "> So the lowly low-density original PC FDD card used DMA and the PC-AT\n",
      "> HDD controller doesn't!?!?  That makes real sense.\n",
      "-- \n",
      "-- -----------------------------------------------------------------------------\n",
      "Guy Dawson - Hoskyns Group Plc.\n",
      "        guyd@hoskyns.co.uk  Tel Hoskyns UK     -  71 251 2128\n",
      "        guyd@austin.ibm.com Tel IBM Austin USA - 512 838 3377\n",
      "\n",
      "-----------------------------------\n",
      "From: Alexander Samuel McDiarmid <am2o+@andrew.cmu.edu>\n",
      "Subject: driver ??\n",
      "Organization: Sophomore, Mechanical Engineering, Carnegie Mellon, Pittsburgh, PA\n",
      "Lines: 15\n",
      "NNTP-Posting-Host: po4.andrew.cmu.edu\n",
      "\n",
      " \n",
      "1)    I have an old Jasmine drive which I cannot use with my new system.\n",
      " My understanding is that I have to upsate the driver with a more modern\n",
      "one in order to gain compatability with system 7.0.1.  does anyone know\n",
      "of an inexpensive program to do this?  ( I have seen formatters for <$20\n",
      "buit have no idea if they will work)\n",
      " \n",
      "2)     I have another ancient device, this one a tape drive for which\n",
      "the back utility freezes the system if I try to use it.  THe drive is a\n",
      "jasmine direct tape (bought used for $150 w/ 6 tapes, techmar\n",
      "mechanism).  Essentially I have the same question as above, anyone know\n",
      "of an inexpensive beckup utility I can use with system 7.0.1\n",
      " \n",
      "all help and advice appriciated.\n",
      "\n",
      "\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "newsgroups = fetch_20newsgroups(subset='all', shuffle=True, random_state=42)\n",
    "\n",
    "df = pd.DataFrame({'text': newsgroups.data, 'target': newsgroups.target})\n",
    "\n",
    "for i in range(5):\n",
    "    print(df['text'][i])\n",
    "    print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b55bc72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\AppData\\Local\\Temp\\ipykernel_8768\\2204915665.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text'] = df['text'].str.replace('[^\\w\\s]',' ')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[from, mamatha, devineni, ratnam, mr47, andrew...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[from, mblawson, midway, ecn, uoknor, edu, mat...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[from, hilmi, er, dsv, su, se, hilmi, eren, su...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[from, guyd, austin, ibm, com, guy, dawson, su...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[from, alexand, samuel, mcdiarmid, am2o, andre...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18841</th>\n",
       "      <td>[from, jim, zisfein, factori, com, jim, zisfei...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18842</th>\n",
       "      <td>[from, rdell, cbnewsf, cb, att, com, richard, ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18843</th>\n",
       "      <td>[from, west, netcom, com, will, est, subject, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18844</th>\n",
       "      <td>[from, steve, hcrlgw, steven, collin, subject,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18845</th>\n",
       "      <td>[from, chriss, netcom, com, chri, silvest, sub...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18846 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target\n",
       "0      [from, mamatha, devineni, ratnam, mr47, andrew...      10\n",
       "1      [from, mblawson, midway, ecn, uoknor, edu, mat...       3\n",
       "2      [from, hilmi, er, dsv, su, se, hilmi, eren, su...      17\n",
       "3      [from, guyd, austin, ibm, com, guy, dawson, su...       3\n",
       "4      [from, alexand, samuel, mcdiarmid, am2o, andre...       4\n",
       "...                                                  ...     ...\n",
       "18841  [from, jim, zisfein, factori, com, jim, zisfei...      13\n",
       "18842  [from, rdell, cbnewsf, cb, att, com, richard, ...      12\n",
       "18843  [from, west, netcom, com, will, est, subject, ...       3\n",
       "18844  [from, steve, hcrlgw, steven, collin, subject,...       1\n",
       "18845  [from, chriss, netcom, com, chri, silvest, sub...       7\n",
       "\n",
       "[18846 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: ''.join(x))\n",
    "df['text'] = df['text'].str.lower()\n",
    "df['text'] = df['text'].str.replace('[^\\w\\s]',' ')\n",
    "df['text'] = df['text'].apply(nltk.word_tokenize)\n",
    "stemmer = nltk.PorterStemmer()\n",
    "df['text'] = df['text'].apply(lambda x :[stemmer.stem(y) for y in x])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35954984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd4c4867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join(x))\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, stop_words='english', use_idf=True)\n",
    "features = vectorizer.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49532781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<18846x149144 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2010664 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(features.toarray(), columns=vectorizer.vocabulary_.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a243e779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train , x_test , y_train , y_test = train_test_split(features,df['target'],test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "335aa619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15076, 149144)\n",
      "(3770, 149144)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<3770x149144 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 410568 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d1da180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM model\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC()\n",
    "svm_model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc567f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy score: 90.84880636604774%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "svm_predicted = svm_model.predict(x_test)\n",
    "test_score = accuracy_score(y_test, svm_predicted) * 100\n",
    "print(f\"SVM accuracy score: {test_score}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7bf52e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c29a4298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy score: 86.57824933687003%\n"
     ]
    }
   ],
   "source": [
    "nb_predicted = nb_model.predict(x_test)\n",
    "test_score = accuracy_score(y_test, nb_predicted) * 100\n",
    "print(f\"Naive Bayes accuracy score: {test_score}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c542dc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(svm_model, 'svm_model.pkl')\n",
    "joblib.dump(nb_model, 'nb_model.pkl')\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07867e57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7f8f93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
